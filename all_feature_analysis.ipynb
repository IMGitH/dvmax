{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0477a01d",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Integrated Dividend Feature Analysis\n",
    "\n",
    "This notebook combines visual correlation analysis, regression diagnostics, and model-based feature importance to analyze the impact of various features on dividend-related metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "import glob\n",
    "\n",
    "# Load all ticker history files\n",
    "history_files = glob.glob(\"features_data/tickers_history/*.parquet\")\n",
    "df_features = pd.concat([pd.read_parquet(f) for f in history_files], ignore_index=True)\n",
    "\n",
    "# Load macroeconomic data\n",
    "df_macro = pd.read_parquet(\"features_data/macro_history/united_states.parquet\")\n",
    "\n",
    "# Load static sector/country info and merge\n",
    "df_static = pd.read_parquet(\"features_data/tickers_static/static_ticker_info.parquet\")\n",
    "df_features = df_features.merge(df_static, on=\"ticker\", how=\"left\")\n",
    "\n",
    "\n",
    "DIVIDEND_FEATURES = [\n",
    "    'dividend_yield',\n",
    "    'dividend_cagr_3y',\n",
    "    'dividend_cagr_5y',\n",
    "    'yield_vs_5y_median'\n",
    "]\n",
    "\n",
    "BINARY_FEATURES = [\n",
    "    'sector_technology', 'sector_healthcare', 'sector_utilities',\n",
    "    'sector_basic_materials', 'sector_financial_services', 'sector_consumer_cyclical',\n",
    "    'sector_real_estate', 'sector_communication_services', 'sector_industrials',\n",
    "    'sector_energy', 'sector_materials', 'sector_consumer_defensive',\n",
    "    'ebit_interest_cover_capped',\n",
    "    'has_eps_cagr_3y', 'has_fcf_cagr_3y', 'has_dividend_yield',\n",
    "    'has_dividend_cagr_3y', 'has_dividend_cagr_5y', 'has_ebit_interest_cover'\n",
    "]\n",
    "\n",
    "EXCLUDE_FEATURES = ['ticker', 'as_of', 'as_of_year', 'country'] + DIVIDEND_FEATURES\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "df_features['as_of'] = pd.to_datetime(df_features['as_of'])\n",
    "df_features['as_of_year'] = df_features['as_of'].dt.year\n",
    "df_features['as_of_year'] = df_features['as_of_year'].astype(df_macro['as_of_year'].dtype)\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_features,\n",
    "    df_macro,\n",
    "    how='left',\n",
    "    on=['as_of_year', 'country']\n",
    ")\n",
    "\n",
    "print(df_merged['gdp_yoy_backfilled'].value_counts(dropna=False))\n",
    "\n",
    "df_merged.drop(columns=['backfilled_year'], errors='ignore', inplace=True)\n",
    "print(\"Data loaded and merged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaaf3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_features countries:\", df_features['country'].unique())\n",
    "print(\"df_macro countries:\", df_macro['country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd69943",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = df_merged.columns.tolist()\n",
    "independent_features = [col for col in all_columns if col not in EXCLUDE_FEATURES]\n",
    "numerical_independent_features = [f for f in independent_features if f not in BINARY_FEATURES]\n",
    "categorical_independent_features = [f for f in independent_features if f in BINARY_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db57f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_categories = {\n",
    "    'Financial_Metrics': [f for f in numerical_independent_features if 'return' in f or 'ratio' in f or 'cagr' in f or 'cover' in f],\n",
    "    'Macro_Economic': ['gdp_yoy_backfilled', 'inflation_latest', 'unemployment_latest', 'consumption_backfilled'],\n",
    "    'Sector_Features': [f for f in df_merged.columns if f.startswith('sector_')]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_feature_impact(target_feature, max_n_plots=10, max_n_importance=10):\n",
    "#     df_analysis = df_merged[df_merged[target_feature].notna()].copy()\n",
    "#     if df_analysis.empty or df_analysis[target_feature].nunique() <= 1:\n",
    "#         print(f\"âš ï¸ '{target_feature}' has insufficient variation. Skipping.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"\\nðŸ” Analyzing: {target_feature}\")\n",
    "\n",
    "#     # === Scatter + Regression plots ===\n",
    "#     for feature in numerical_independent_features:\n",
    "#         if (\n",
    "#             feature in df_analysis.columns\n",
    "#             and df_analysis[feature].notna().sum() >= 3\n",
    "#             and df_analysis[feature].nunique() > 2\n",
    "#             and not feature.endswith('_capped')\n",
    "#             and not feature.startswith('has_')\n",
    "#         ):\n",
    "#             plt.figure(figsize=(7, 4))\n",
    "#             sns.scatterplot(x=feature, y=target_feature, data=df_analysis, alpha=0.6)\n",
    "#             sns.regplot(x=feature, y=target_feature, data=df_analysis, scatter=False, color='red', line_kws={'alpha': 0.6})\n",
    "#             plt.title(f'{target_feature} vs. {feature}')\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "\n",
    "#     # === One-hot sector to single column ===\n",
    "#     sector_columns = [f for f in df_analysis.columns if f.startswith(\"sector_\")]\n",
    "#     if sector_columns:\n",
    "#         df_analysis['sector'] = df_analysis[sector_columns].idxmax(axis=1).str.replace('sector_', '').str.title()\n",
    "#         df_analysis.drop(columns=sector_columns, inplace=True)\n",
    "#         if df_analysis['sector'].nunique() > 1:\n",
    "#             plt.figure(figsize=(10, 5))\n",
    "#             sns.boxplot(x='sector', y=target_feature, data=df_analysis)\n",
    "#             plt.title(f'{target_feature} distribution by sector')\n",
    "#             plt.xticks(rotation=45)\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "\n",
    "#     # === Boxplots for binary categorical features ===\n",
    "#     for feature in categorical_independent_features:\n",
    "#         if (\n",
    "#             feature in df_analysis.columns\n",
    "#             and not feature.startswith('has_')\n",
    "#             and not feature.endswith('_capped')\n",
    "#         ):\n",
    "#             df_analysis[feature] = df_analysis[feature].astype('category')\n",
    "#             if df_analysis[feature].nunique() <= 1:\n",
    "#                 continue\n",
    "#             value_counts = df_analysis[feature].value_counts(normalize=True)\n",
    "#             if value_counts.iloc[0] > 0.95:\n",
    "#                 continue  # Skip if imbalanced\n",
    "#             plt.figure(figsize=(7, 4))\n",
    "#             sns.boxplot(x=feature, y=target_feature, data=df_analysis)\n",
    "#             plt.title(f'{target_feature} distribution by {feature}')\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "\n",
    "#     # === Correlation Bar Plots ===\n",
    "#     fig, axes = plt.subplots(1, len(predictor_categories), figsize=(5 * len(predictor_categories), 4))\n",
    "#     if len(predictor_categories) == 1:\n",
    "#         axes = [axes]\n",
    "\n",
    "#     for ax, (group_name, group_features) in zip(axes, predictor_categories.items()):\n",
    "#         valid_feats = [\n",
    "#             f for f in group_features if (\n",
    "#                 f in df_analysis.columns and \n",
    "#                 df_analysis[f].notna().sum() > 2 and \n",
    "#                 not f.startswith('has_') and \n",
    "#                 not f.endswith('_capped') and \n",
    "#                 not f.startswith('sector_')\n",
    "#             )\n",
    "#         ]\n",
    "#         if not valid_feats:\n",
    "#             ax.set_visible(False)\n",
    "#             continue\n",
    "#         data_for_corr = df_analysis[valid_feats + [target_feature]].dropna()\n",
    "#         if data_for_corr.shape[0] < 3:\n",
    "#             ax.set_visible(False)\n",
    "#             continue\n",
    "#         corr_vals = data_for_corr.corr()[target_feature].drop(target_feature).dropna()\n",
    "#         corr_vals = corr_vals.sort_values(key=np.abs, ascending=False).head(max_n_plots)\n",
    "#         colors = ['red' if v < 0 else 'blue' for v in corr_vals]\n",
    "#         ax.barh(corr_vals.index.str.replace('_', ' ').str.title(), corr_vals.values, color=colors)\n",
    "#         ax.set_title(f\"{group_name} Correlation\")\n",
    "#         ax.axvline(0, color='black', lw=0.8)\n",
    "#         ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # === Random Forest Feature Importance ===\n",
    "#     rf_features = [\n",
    "#         f for group in predictor_categories.values() for f in group if (\n",
    "#             f in df_analysis.columns and\n",
    "#             not f.endswith('_capped') and\n",
    "#             not f.startswith('has_') and\n",
    "#             not f.startswith('sector_')\n",
    "#         )\n",
    "#     ]\n",
    "#     model_data = df_analysis[rf_features + [target_feature]].dropna()\n",
    "#     if len(model_data) < 10:\n",
    "#         print(\"Not enough data for modeling.\")\n",
    "#         return\n",
    "\n",
    "#     X = model_data[rf_features].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "#     y = model_data.loc[X.index, target_feature]\n",
    "\n",
    "#     if X.shape[1] < 2:\n",
    "#         print(\"âš ï¸ Too few features with valid data for modeling.\")\n",
    "#         return\n",
    "\n",
    "#     rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "#     rf_model.fit(X, y)\n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'Feature': X.columns,\n",
    "#         'Importance': rf_model.feature_importances_\n",
    "#     }).sort_values('Importance', ascending=False).head(max_n_importance)\n",
    "\n",
    "#     # === Print top correlations ===\n",
    "#     numeric_cols = df_analysis.select_dtypes(include=[np.number]).columns\n",
    "#     if target_feature not in numeric_cols:\n",
    "#         print(f\"âš ï¸ '{target_feature}' is not numeric. Skipping correlation summary.\")\n",
    "#     else:\n",
    "#         correlation_series = df_analysis[numeric_cols].corr()[target_feature].drop(target_feature).dropna()\n",
    "#         top_corrs = correlation_series.abs().sort_values(ascending=False).head(5)\n",
    "#         print(f\"ðŸ“Œ Top correlations with {target_feature}:\\n{top_corrs}\")\n",
    "\n",
    "#     # === Plot Feature Importance ===\n",
    "#     fig, ax = plt.subplots(figsize=(8, 0.3 * len(importance_df)))\n",
    "#     colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "#     bars = ax.barh(range(len(importance_df)), importance_df['Importance'], color=colors)\n",
    "\n",
    "#     ax.set_yticks(range(len(importance_df)))\n",
    "#     ax.set_yticklabels([f.replace('_', ' ').title() for f in importance_df['Feature']])\n",
    "#     ax.set_xlabel('Feature Importance (Random Forest)')\n",
    "#     ax.set_title(f'Feature Importance for Predicting {target_feature.replace(\"_\", \" \").title()}')\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "\n",
    "#     for bar, importance in zip(bars, importance_df['Importance']):\n",
    "#         ax.text(importance + 0.001, bar.get_y() + bar.get_height() / 2,\n",
    "#                 f'{importance:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     print(f\"Model RÂ² Score: {r2_score(y, rf_model.predict(X)):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c722fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_regression(df, target_feature, numerical_features):\n",
    "    for feature in numerical_features:\n",
    "        if (\n",
    "            feature in df.columns\n",
    "            and df[feature].notna().sum() >= 3\n",
    "            and df[feature].nunique() > 2\n",
    "            and not feature.endswith('_capped')\n",
    "            and not feature.startswith('has_')\n",
    "        ):\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            sns.scatterplot(x=feature, y=target_feature, data=df, alpha=0.6)\n",
    "            sns.regplot(x=feature, y=target_feature, data=df, scatter=False, color='red', line_kws={'alpha': 0.6})\n",
    "            plt.title(f'{target_feature} vs. {feature}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "def plot_sector_boxplot(df, target_feature):\n",
    "    sector_columns = [f for f in df.columns if f.startswith(\"sector_\")]\n",
    "    if sector_columns:\n",
    "        df['sector'] = df[sector_columns].idxmax(axis=1).str.replace('sector_', '').str.title()\n",
    "        df.drop(columns=sector_columns, inplace=True)\n",
    "        if df['sector'].nunique() > 1:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.boxplot(x='sector', y=target_feature, data=df)\n",
    "            plt.title(f'{target_feature} distribution by sector')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    return df\n",
    "\n",
    "def plot_binary_categorical_boxplots(df, target_feature, categorical_features):\n",
    "    for feature in categorical_features:\n",
    "        if (\n",
    "            feature in df.columns\n",
    "            and not feature.startswith('has_')\n",
    "            and not feature.endswith('_capped')\n",
    "        ):\n",
    "            df[feature] = df[feature].astype('category')\n",
    "            if df[feature].nunique() <= 1:\n",
    "                continue\n",
    "            value_counts = df[feature].value_counts(normalize=True)\n",
    "            if value_counts.iloc[0] > 0.95:\n",
    "                continue\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            sns.boxplot(x=feature, y=target_feature, data=df)\n",
    "            plt.title(f'{target_feature} distribution by {feature}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "def plot_correlations(df, target_feature, predictor_categories, max_n_plots):\n",
    "    fig, axes = plt.subplots(1, len(predictor_categories), figsize=(5 * len(predictor_categories), 4))\n",
    "    if len(predictor_categories) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (group_name, group_features) in zip(axes, predictor_categories.items()):\n",
    "        valid_feats = [\n",
    "            f for f in group_features if (\n",
    "                f in df.columns and \n",
    "                df[f].notna().sum() > 2 and \n",
    "                not f.startswith('has_') and \n",
    "                not f.endswith('_capped') and \n",
    "                not f.startswith('sector_')\n",
    "            )\n",
    "        ]\n",
    "        if not valid_feats:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "        data_for_corr = df[valid_feats + [target_feature]].dropna()\n",
    "        if data_for_corr.shape[0] < 3:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "        corr_vals = data_for_corr.corr()[target_feature].drop(target_feature).dropna()\n",
    "        corr_vals = corr_vals.sort_values(key=np.abs, ascending=False).head(max_n_plots)\n",
    "        colors = ['red' if v < 0 else 'blue' for v in corr_vals]\n",
    "        ax.barh(corr_vals.index.str.replace('_', ' ').str.title(), corr_vals.values, color=colors)\n",
    "        ax.set_title(f\"{group_name} Correlation\")\n",
    "        ax.axvline(0, color='black', lw=0.8)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_random_forest_importance(df, target_feature, predictor_categories, max_n_importance):\n",
    "    rf_features = [\n",
    "        f for group in predictor_categories.values() for f in group if (\n",
    "            f in df.columns and\n",
    "            not f.endswith('_capped') and\n",
    "            not f.startswith('has_') and\n",
    "            not f.startswith('sector_')\n",
    "        )\n",
    "    ]\n",
    "    model_data = df[rf_features + [target_feature]].dropna()\n",
    "    if len(model_data) < 10:\n",
    "        print(\"Not enough data for modeling.\")\n",
    "        return\n",
    "\n",
    "    X = model_data[rf_features].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y = model_data.loc[X.index, target_feature]\n",
    "\n",
    "    if X.shape[1] < 2:\n",
    "        print(\"âš ï¸ Too few features with valid data for modeling.\")\n",
    "        return\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X, y)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False).head(max_n_importance)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 0.3 * len(importance_df)))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "    bars = ax.barh(range(len(importance_df)), importance_df['Importance'], color=colors)\n",
    "\n",
    "    ax.set_yticks(range(len(importance_df)))\n",
    "    ax.set_yticklabels([f.replace('_', ' ').title() for f in importance_df['Feature']])\n",
    "    ax.set_xlabel('Feature Importance (Random Forest)')\n",
    "    ax.set_title(f'Feature Importance for Predicting {target_feature.replace(\"_\", \" \").title()}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    for bar, importance in zip(bars, importance_df['Importance']):\n",
    "        ax.text(importance + 0.001, bar.get_y() + bar.get_height() / 2,\n",
    "                f'{importance:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Model RÂ² Score: {r2_score(y, rf_model.predict(X)):.3f}\")\n",
    "    return importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_impact(target_feature):\n",
    "    df_analysis = df_merged[df_merged[target_feature].notna()].copy()\n",
    "    if df_analysis.empty or df_analysis[target_feature].nunique() <= 1:\n",
    "        print(f\"âš ï¸ '{target_feature}' has insufficient variation. Skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nðŸ” Analyzing: {target_feature}\")\n",
    "    plot_scatter_regression(df_analysis, target_feature, numerical_independent_features)\n",
    "    df_analysis = plot_sector_boxplot(df_analysis, target_feature)\n",
    "    plot_binary_categorical_boxplots(df_analysis, target_feature, categorical_independent_features)\n",
    "    plot_correlations(df_analysis, target_feature, predictor_categories, max_n_plots=10)\n",
    "    plot_random_forest_importance(df_analysis, target_feature, predictor_categories, max_n_importance=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13afc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in DIVIDEND_FEATURES:\n",
    "    print (f\"\\n\\n{'=' * 40}\\nAnalyzing feature: {target}\\n{'=' * 40}\")\n",
    "    analyze_feature_impact(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target in DIVIDEND_FEATURES:\n",
    "#     analyze_feature_impact(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59c563",
   "metadata": {},
   "source": [
    "### ðŸ”¥ Partial Correlation Heatmap using valid features only\n",
    "ðŸ” What this does:\n",
    "- Computes pairwise correlations.\n",
    "- Selects only features with at least one absolute correlation â‰¥ 0.3 to a dividend feature.\n",
    "- Shows a cleaner, interpretable heatmap using clustermap (which groups similar variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_features = DIVIDEND_FEATURES + numerical_independent_features\n",
    "valid_corr_features = [\n",
    "    col for col in correlation_features\n",
    "    if col in df_merged.columns and df_merged[col].dtype in ['float64', 'float32', 'int64']\n",
    "]\n",
    "\n",
    "# Keep only columns with â‰¥5 non-NaN values\n",
    "valid_counts = df_merged[valid_corr_features].notna().sum()\n",
    "selected_features = valid_counts[valid_counts >= 5].index.tolist()\n",
    "\n",
    "# Configuration\n",
    "target_features = DIVIDEND_FEATURES\n",
    "threshold = 0.3  # Adjust this threshold as needed\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_merged[selected_features].corr()\n",
    "\n",
    "# Identify features with at least one strong correlation with any dividend feature\n",
    "strong_corrs = corr_matrix[target_features].abs().max(axis=1)\n",
    "filtered_features = strong_corrs[strong_corrs >= threshold].index.tolist()\n",
    "\n",
    "# If nothing is found, fallback to a warning\n",
    "if len(filtered_features) < 2:\n",
    "    print(f\"âš ï¸ No features found with |correlation| â‰¥ {threshold} to any dividend feature.\")\n",
    "else:\n",
    "    # Compute filtered correlation matrix\n",
    "    filtered_corr = df_merged[filtered_features].corr()\n",
    "\n",
    "    # Optional: cluster to improve interpretability\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        sns.clustermap(\n",
    "            filtered_corr,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            linewidths=0.5,\n",
    "            figsize=(12, 10)\n",
    "        )\n",
    "        plt.title(f\"Filtered Correlation Heatmap (|r| â‰¥ {threshold})\", pad=80)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to render heatmap: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f7568",
   "metadata": {},
   "source": [
    "### ðŸ“Œ **Top Insights on Dividend Features**\n",
    "\n",
    "#### 1. **Dividend Yield**\n",
    "\n",
    "* Strong **positive correlation** with:\n",
    "\n",
    "  * `payout_ratio` (r â‰ˆ 0.73)\n",
    "  * `net_debt_to_ebitda` (r â‰ˆ 0.57)\n",
    "* Strong **negative correlation** with:\n",
    "\n",
    "  * `sma_50_200_delta`, `fcf_cagr_3y`, and `volatility` (r â‰ˆ -0.5 to -0.6)\n",
    "\n",
    "ðŸ§  *Interpretation*: High dividend yield tends to occur in **financially mature, lower-growth stocks** with higher debt and slower momentum.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Dividend CAGR (3Y, 5Y)**\n",
    "\n",
    "* Strong **positive correlation** with:\n",
    "\n",
    "  * `fcf_cagr_3y`, `eps_cagr_3y` (r â‰ˆ 0.8+)\n",
    "  * `sma_50_200_delta`, `6m_return`, `12m_return` (r â‰ˆ 0.5â€“0.8)\n",
    "\n",
    "ðŸ§  *Interpretation*: Sustained dividend growth is **highly aligned with earnings and cash flow growth**, and coincides with **positive price momentum**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Yield vs. 5Y Median**\n",
    "\n",
    "* Strong **negative correlation** with:\n",
    "\n",
    "  * `fcf_cagr_3y`, `dividend_cagr_5y`, `sma_50_200_delta` (r â‰ˆ -0.5 to -0.8)\n",
    "\n",
    "ðŸ§  *Interpretation*: When dividend growth and performance are high, yields tend to be **compressed vs. historical median**, likely due to price appreciation.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¥ Additional Highlights\n",
    "\n",
    "* `fcf_cagr_3y` and `eps_cagr_3y` are **core growth drivers**, highly correlated with most dividend-growth indicators.\n",
    "* `sector_relative_6m` and `sma_50_200_delta` are also informative of dividend trends, linking **technical momentum** to dividend behaviors.\n",
    "* `net_debt_to_ebitda` shows up as a red flag for **high yield but low growth**, supporting a â€œvalue trapâ€ narrative in some cases.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”š Summary\n",
    "\n",
    "* **Yield**: linked to **debt, payout, and negative momentum**.\n",
    "* **Growth**: driven by **fundamentals (FCF, EPS)** and **positive technicals**.\n",
    "* **Over-yielding**: may signal **underperformance or risk**, not opportunity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
