name: Generate Macro & Ticker Features

on:
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: features-${{ github.ref }}
  cancel-in-progress: false

jobs:
  generate:
    permissions:
      contents: read
      issues: write
    runs-on: ubuntu-latest
    timeout-minutes: 120
    env:
      PYTHON_VERSION: "3.11"
      OVERWRITE_MODE: "append"
      STRICT: "1"
      
    steps:
      - name: â¬‡ï¸ Checkout
        uses: actions/checkout@v4

      - name: ğŸ“ Prepare isolated data root
        env:
          DATA_ROOT: ${{ runner.temp }}/features_data
        run: |
          set -e
          mkdir -p "${DATA_ROOT}"
          # Keep existing paths working by symlinking:
          rm -rf features_data 2>/dev/null || true
          ln -s "${DATA_ROOT}" features_data
          echo "DATA_ROOT=${DATA_ROOT}" >> $GITHUB_ENV

      - name: ğŸ§ª Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ—„ï¸ Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            pip-

      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # â™»ï¸ Restore snapshot strictly from the latest Release
      - name: â™»ï¸ Restore snapshot (Release only)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          DATA_ROOT="${DATA_ROOT:-${RUNNER_TEMP}/features_data}"
          mkdir -p "$DATA_ROOT"
          dl="${RUNNER_TEMP}/release_dl"
          mkdir -p "$dl"

          # Find most recent published, non-prerelease release with a "data-" tag
          tag=$(gh release list --limit 30 --json tagName,isDraft,isPrerelease,publishedAt \
            --jq '[.[] | select(.isDraft==false and .isPrerelease==false and (.tagName|startswith("data-")))] 
                  | sort_by(.publishedAt) 
                  | last.tagName' || true)

          if [ -z "${tag:-}" ] || [ "${tag}" = "null" ]; then
            echo "No suitable Release found; starting fresh."
            exit 0
          fi

          echo "Using Release: $tag"
          gh release download "$tag" -p 'features_*.tar.gz' -D "$dl"

          tgz=$(ls -1 "$dl"/features_*.tar.gz 2>/dev/null | head -n1 || true)
          if [ -z "${tgz:-}" ]; then
            echo "No features_*.tar.gz asset in $tag; starting fresh."
            exit 0
          fi

          echo "Downloaded: $tgz"
          echo "sha256: $(sha256sum "$tgz" | cut -d' ' -f1)"

          # Extract directly into DATA_ROOT (tarball contains top-level dirs)
          tar -xzf "$tgz" -C "$DATA_ROOT"

          echo "Restored tree:"
          ls -R "$DATA_ROOT" || true

      # ğŸ”¹ Run macro ALWAYS (it's not related to FMP)
      - name: ğŸ§® Run macro batch generation
        env:
          PYTHONPATH: .
        run: python src/dataprep/features/aggregation/macro_batch_runner.py

      # Now preflight only for the ticker part
      - name: ğŸ” FMP preflight
        id: preflight
        env:
          PYTHONPATH: .
          FMP_API_KEY: ${{ secrets.FMP_API_KEY }}
        continue-on-error: true
        run: |
          set -eo pipefail
          code=0
          kind="OK"
          if python tools/fmp_preflight.py | tee preflight.log; then
            code=0; kind="OK"
          else
            code=${PIPESTATUS[0]:-1}
            if [ -f preflight.log ]; then
              kind=$(cut -d: -f1 preflight.log | head -n1 || echo "OTHER")
            else
              kind="OTHER"
            fi
          fi
          echo "code=$code" >> "$GITHUB_OUTPUT"
          echo "kind=$kind" >> "$GITHUB_OUTPUT"
          exit $code

      - name: âŒ Stop on hard FMP failures
        if: steps.preflight.outputs.code != '0' && (steps.preflight.outputs.kind == 'PLAN' || steps.preflight.outputs.kind == 'AUTH')
        run: |
          echo "Hard failure: ${{ steps.preflight.outputs.kind }} â€” not retryable."
          exit 1

      # ğŸ”¹ Ticker generation only when preflight is OK / retryable
      - name: ğŸ§® Run ticker batch generation
        if: steps.preflight.outputs.kind == 'OK' || steps.preflight.outputs.kind == 'RATE' || steps.preflight.outputs.kind == 'SERVER' || steps.preflight.outputs.kind == 'OTHER'
        env:
          PYTHONPATH: .
          FMP_API_KEY: ${{ secrets.FMP_API_KEY }}
          FORCE_MERGE: "0"
          OVERWRITE_MODE: "append"
        run: python src/dataprep/features/aggregation/ticker_batch_runner.py

      - name: ğŸ—‚ï¸ Build processed tickers ledger
        if: always()
        run: |
          python - <<'PY'
          import json, glob
          from pathlib import Path
          done = { Path(p).stem: "ok" for p in glob.glob("features_data/tickers_history/*.parquet") }
          Path("features_data/status").mkdir(parents=True, exist_ok=True)
          Path("features_data/status/processed.json").write_text(json.dumps(done, indent=2))
          print("Wrote features_data/status/processed.json with", len(done), "tickers")
          PY

      - name: ğŸ§ª Show validation flags
        if: always()
        run: |
          echo "ğŸ” Checking for soft validation flags..."
          if compgen -G "features_data/_audit/*.txt" > /dev/null; then
            echo "âš ï¸ Flagged rows:"
            for f in features_data/_audit/*.txt; do
              echo ""
              echo "----- $(basename "$f") -----"
              cat "$f"
            done
          else
            echo "âœ… No flags."
          fi

      - name: ğŸ› ï¸ Install jq for JSON processing
        if: always()
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: ğŸ“‹ Append live progress to summary
        if: always()
        run: |
          if [ -f features_data/status/progress.json ]; then
            echo "## Data Progress" >> $GITHUB_STEP_SUMMARY
            echo "- Percent: $(jq -r .percent features_data/status/progress.json)%" >> $GITHUB_STEP_SUMMARY
            echo "- Processed: $(jq -r .counts.processed features_data/status/progress.json)/$(jq -r .totals.total_tasks features_data/status/progress.json)" >> $GITHUB_STEP_SUMMARY
            echo "- Flagged: $(jq -r .counts.flagged features_data/status/progress.json)" >> $GITHUB_STEP_SUMMARY
            echo "- Failed: $(jq -r .counts.failed features_data/status/progress.json)" >> $GITHUB_STEP_SUMMARY
            echo "- ETA (UTC): $(jq -r .eta_utc features_data/status/progress.json)" >> $GITHUB_STEP_SUMMARY
          else
            echo "No progress.json found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ğŸ“¨ Notify Progress via GitHub Issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = 'features_data/status/progress.json';
            if (!fs.existsSync(path)) {
              core.info('progress.json not found; skipping issue notification.');
              return;
            }
            const p = JSON.parse(fs.readFileSync(path,'utf8'));
            const title = `Data snapshot ready: ${p.percent}% processed`;
            const body = `**Data snapshot completed**
            - Percent: ${p.percent}%
            - Processed: ${p.counts.processed}/${p.totals.total_tasks}
            - Flagged: ${p.counts.flagged}
            - Failed: ${p.counts.failed}
            - ETA (UTC): ${p.eta_utc}

            cc @your-github-handle`;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title, body
            });

      - name: ğŸ¯ Threshold milestones
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (!fs.existsSync('features_data/status/progress.json')) return;
            const p = JSON.parse(fs.readFileSync('features_data/status/progress.json','utf8'));
            const percent = Math.floor(p.percent || 0);
            const hit = [50, 90].includes(percent);
            if (!hit) return;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Milestone ${percent}% reached`,
              body: `Processed ${p.counts.processed}/${p.totals.total_tasks} | Failed ${p.counts.failed} | ETA ${p.eta_utc || 'n/a'}`
            });

      - name: ğŸ“ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: |
            preflight.log
            **/*.log
            features_data/status/*.json
            features_data/_audit/*.txt
          if-no-files-found: ignore
          retention-days: 7


      - name: ğŸ’¾ Upload partial results on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: features_partial
          path: |
            features_data/macro_history
            features_data/tickers_history
            features_data/tickers_static
            features_data/status
            features_data/_audit
          if-no-files-found: ignore
          retention-days: 7

      # ğŸ“¦ Package outputs from DATA_ROOT, not repo
      - name: ğŸ“¦ Package outputs
        id: package
        if: success()
        run: |
          set -e
          ts=$(date -u +'%Y%m%d_%H%M%S')
          echo "TS=$ts" >> $GITHUB_OUTPUT
          # Build a clean payload under $RUNNER_TEMP and tar it
          pkg_dir="${RUNNER_TEMP}/pkg_${ts}"
          mkdir -p "$pkg_dir"
          for d in macro_history tickers_history tickers_static status _audit; do
            if [ -d "${DATA_ROOT}/${d}" ]; then
              mkdir -p "${pkg_dir}/${d}"
              cp -R "${DATA_ROOT}/${d}/." "${pkg_dir}/${d}/"
            fi
          done
          tar -czf "features_${ts}.tar.gz" -C "${pkg_dir}" .
          ls -lh "features_${ts}.tar.gz"

      - name: ğŸ·ï¸ Create release & upload asset
        if: success()
        uses: softprops/action-gh-release@v2
        with:
          tag_name: data-${{ steps.package.outputs.TS }}
          name: "Data snapshot ${{ steps.package.outputs.TS }}"
          body: |
            Automated data snapshot.
            - Timestamp (UTC): ${{ steps.package.outputs.TS }}
            - OVERWRITE_MODE: ${{ env.OVERWRITE_MODE }}
          files: |
            features_${{ steps.package.outputs.TS }}.tar.gz

      # â• Optional: also publish a cross-run artifact named 'features_latest'
      - name: ğŸ“¤ Publish cross-run artifact alias
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: features_latest
          path: features_${{ steps.package.outputs.TS }}.tar.gz
          retention-days: 30
          